{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cleandata import add_impact_score, get_data, plot_grouped_impact_scores, remove_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n",
    "df = add_impact_score(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eba4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_impact_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's reload the data to see what we're working with\n",
    "df = get_data()\n",
    "df = add_impact_score(df)\n",
    "df = remove_outliers(df)\n",
    "\n",
    "# Check the unique values in graduation year column\n",
    "# print(\"Unique graduation years:\")\n",
    "# print(df['años de graduación'].value_counts())\n",
    "# print(f\"\\nTotal rows before filtering: {len(df)}\")\n",
    "\n",
    "# Check how many rows would be removed\n",
    "# rows_to_remove = df[(df['años de graduación'] == 2022) | (df['años de graduación'] == 'Sin dato')]\n",
    "# print(f\"Rows that would be removed: {len(rows_to_remove)}\")\n",
    "\n",
    "# Apply the filter\n",
    "df_filtered = df[~((df['años de graduación'] == '2022') |\n",
    "                   (df['años de graduación'] == 'Sin dato'))]\n",
    "print(f\"Rows remaining after filtering: {len(df_filtered)}\")\n",
    "\n",
    "# Plot with the filtered data\n",
    "if len(df_filtered) > 0:\n",
    "    plot_grouped_impact_scores(df_filtered)\n",
    "else:\n",
    "    print(\"No data remaining after filtering. Consider adjusting the filter criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba74904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1, len(pd.read_csv('80QS.csv')))\n",
    "print(2, len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.unique(df_filtered['años de graduación'], return_counts=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=X, y=Y, palette='viridis')\n",
    "plt.title('Graduation Year Distribution')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graduation_year_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a83b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data for regression\n",
    "grouped = df_filtered.groupby('años de graduación')[\n",
    "    'impact_score'].sum().reset_index()\n",
    "X = grouped['años de graduación'].values.reshape(-1, 1)\n",
    "y = grouped['impact_score'].values\n",
    "# Convert years to numeric values\n",
    "X = X.astype(float)\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "# X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the first 90% of the data for training and the last 10% for testing\n",
    "split_index = int(len(X) * 0.9)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Create and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "# Plot the regression results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars\n",
    "plt.bar(X.flatten(), y, color='blue', alpha=0.5, label='Actual')\n",
    "# Plot regression line\n",
    "X_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_range_pred = model.predict(X_range)\n",
    "plt.plot(X_range.flatten(), y_range_pred, color='red',\n",
    "         linewidth=2, label='Regression Line')\n",
    "# Plot test predictions\n",
    "plt.scatter(X_test.flatten(), y_pred, color='orange',\n",
    "            s=50, label='Test Predictions', zorder=5)\n",
    "plt.title('Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('impact_score_vs_graduation_year.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Prepare the data for ARIMA\n",
    "grouped = df_filtered.groupby('años de graduación')[\n",
    "    'impact_score'].sum().reset_index()\n",
    "# Convert years to datetime format\n",
    "grouped['años de graduación'] = pd.to_datetime(\n",
    "    grouped['años de graduación'], format='%Y', errors='coerce')\n",
    "# Set the index to the graduation year\n",
    "grouped.set_index('años de graduación', inplace=True)\n",
    "# Ensure the index is sorted\n",
    "grouped.sort_index(inplace=True)\n",
    "print(\"Grouped Data for ARIMA:\")\n",
    "print(grouped.head())\n",
    "# Fit the ARIMA model\n",
    "model = ARIMA(grouped['impact_score'], order=(0, 1, 5))\n",
    "model_fit = model.fit()\n",
    "# Make predictions\n",
    "# for each year in the next 5 years\n",
    "forecast = model_fit.forecast(steps=5)\n",
    "# Print the forecasted values\n",
    "print(\"ARIMA Forecast for the next 5 years:\")\n",
    "print(forecast)\n",
    "# Create future dates for forecasting\n",
    "last_date = grouped.index[-1]\n",
    "future_dates = pd.date_range(\n",
    "    start=last_date + pd.DateOffset(years=1), periods=5, freq='YE')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plot historical data using the index (which is now the datetime)\n",
    "plt.plot(grouped.index, grouped['impact_score'],\n",
    "         label='Historical Data', color='blue', marker='o')\n",
    "\n",
    "# Plot forecast\n",
    "plt.plot(future_dates, forecast,\n",
    "         label='ARIMA Forecast', color='red', marker='s', linestyle='--')\n",
    "\n",
    "plt.title('ARIMA Forecast of Impact Score')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('arima_forecast_impact_score.png')\n",
    "plt.show()\n",
    "\n",
    "# Print the forecast with corresponding years\n",
    "print(\"\\nDetailed Forecast:\")\n",
    "for i, (date, value) in enumerate(zip(future_dates, forecast)):\n",
    "    print(f\"Year {date.year}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35548707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression (SVR)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare the data for SVR - use year values instead of datetime\n",
    "grouped_reset = grouped.reset_index()\n",
    "grouped_reset['year'] = grouped_reset['años de graduación'].dt.year\n",
    "\n",
    "X = grouped_reset['year'].values.reshape(-1, 1)\n",
    "y = grouped_reset['impact_score'].values\n",
    "\n",
    "# Scale the features for better SVR performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, random_state=42)\n",
    "len_data = len(X_scaled)\n",
    "X_train, X_test, y_train, y_test = X_scaled[:int(\n",
    "    len_data*0.9)], X_scaled[int(len_data*0.9):], y[:int(len_data*0.9)], y[int(len_data*0.9):]\n",
    "\n",
    "# Create and fit the SVR model\n",
    "svr_model = SVR(kernel='rbf', C=10000000, gamma='scale', epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_svr_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVR model\n",
    "mse_svr = mean_squared_error(y_test, y_svr_pred)\n",
    "r2_svr = r2_score(y_test, y_svr_pred)\n",
    "print(f'SVR Mean Squared Error: {mse_svr}')\n",
    "print(f'SVR R-squared: {r2_svr}')\n",
    "\n",
    "# Plot the SVR results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual data as bars using year values\n",
    "years = grouped_reset['year'].values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_svr_pred, color='orange',\n",
    "            s=50, label='SVR Predictions', zorder=5)\n",
    "\n",
    "# Plot SVR line\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range)\n",
    "y_svr_range_pred = svr_model.predict(X_range_scaled)\n",
    "plt.plot(X_range.flatten(), y_svr_range_pred,\n",
    "         color='green', linewidth=2, label='SVR Line')\n",
    "\n",
    "plt.title('SVR Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict 5 more years into the future\n",
    "future_years = np.array([2022, 2023, 2024, 2025, 2026,\n",
    "                        2027, 2028, 2029, 2030]).reshape(-1, 1)\n",
    "future_years_scaled = scaler.transform(future_years)\n",
    "future_predictions = svr_model.predict(future_years_scaled)\n",
    "\n",
    "print(\"\\nSVR Forecast for the next 5 years:\")\n",
    "for year, prediction in zip(future_years.flatten(), future_predictions):\n",
    "    print(f\"Year {year}: {prediction:.2f}\")\n",
    "\n",
    "# Plot with future predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Historical Data')\n",
    "plt.scatter(future_years.flatten(), future_predictions,\n",
    "            color='red', s=100, label='Future Predictions', marker='s')\n",
    "plt.plot(X_range.flatten(), y_svr_range_pred,\n",
    "         color='green', linewidth=2, label='SVR Line')\n",
    "\n",
    "plt.title('SVR Impact Score Forecast')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=1000)\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "# Evaluate the Random Forest model\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "r2_rf = r2_score(y_test, y_rf_pred)\n",
    "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
    "print(f'Random Forest R-squared: {r2_rf}')\n",
    "# Plot the Random Forest results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars using year values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_rf_pred, color='orange',\n",
    "            s=50, label='RF Predictions', zorder=5)\n",
    "# Plot Random Forest line\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range)\n",
    "y_rf_range_pred = rf_model.predict(X_range_scaled)\n",
    "plt.plot(X_range.flatten(), y_rf_range_pred,\n",
    "         color='purple', linewidth=2, label='RF Line')\n",
    "plt.title('Random Forest Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Compare models\n",
    "models = {\n",
    "    'Linear Regression': (mse, r2),\n",
    "    'SVR': (mse_svr, r2_svr),\n",
    "    'Random Forest': (mse_rf, r2_rf)\n",
    "}\n",
    "print(\"\\nModel Comparison:\")\n",
    "for model_name, (mse_value, r2_value) in models.items():\n",
    "    print(f\"{model_name} - Mean Squared Error: {mse_value:.2f}, R-squared: {r2_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning - Improved CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Prepare the data for CNN with better preprocessing\n",
    "# Use the scaled data from SVR\n",
    "# Reshape for CNN (samples, timesteps, features)\n",
    "X_cnn = X_scaled.reshape(-1, 1, 1)\n",
    "y_cnn = y\n",
    "\n",
    "# Use the same train/test split as other models for fair comparison\n",
    "X_cnn_train = X_cnn[:len_data//10*9]\n",
    "X_cnn_test = X_cnn[len_data//10*9:]\n",
    "y_cnn_train = y_cnn[:len_data//10*9]\n",
    "y_cnn_test = y_cnn[len_data//10*9:]\n",
    "\n",
    "# Create an improved CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(1, 1)),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile with better parameters\n",
    "cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit the model with validation split\n",
    "history = cnn_model.fit(\n",
    "    X_cnn_train, y_cnn_train,\n",
    "    epochs=1000,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_cnn_pred = cnn_model.predict(X_cnn_test).flatten()\n",
    "\n",
    "# Evaluate the CNN model\n",
    "mse_cnn = mean_squared_error(y_cnn_test, y_cnn_pred)\n",
    "r2_cnn = r2_score(y_cnn_test, y_cnn_pred)\n",
    "print(f'Improved CNN Mean Squared Error: {mse_cnn}')\n",
    "print(f'Improved CNN R-squared: {r2_cnn}')\n",
    "\n",
    "# Plot the CNN results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot actual data as bars\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "\n",
    "# Get corresponding years for test predictions\n",
    "X_cnn_test_years = scaler.inverse_transform(X_cnn_test.reshape(-1, 1))\n",
    "plt.scatter(X_cnn_test_years.flatten(), y_cnn_pred, color='orange',\n",
    "            s=100, label='CNN Predictions', zorder=5)\n",
    "\n",
    "# Plot CNN line for the full range\n",
    "X_range_cnn = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_cnn_scaled = scaler.transform(X_range_cnn).reshape(-1, 1, 1)\n",
    "y_cnn_range_pred = cnn_model.predict(X_range_cnn_scaled).flatten()\n",
    "plt.plot(X_range_cnn.flatten(), y_cnn_range_pred,\n",
    "         color='cyan', linewidth=2, label='CNN Line')\n",
    "\n",
    "plt.title('Improved CNN Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict future values\n",
    "future_years_cnn_scaled = scaler.transform(future_years).reshape(-1, 1, 1)\n",
    "future_cnn_predictions = cnn_model.predict(future_years_cnn_scaled).flatten()\n",
    "\n",
    "print(\"\\nCNN Forecast for future years:\")\n",
    "for year, prediction in zip(future_years.flatten(), future_cnn_predictions):\n",
    "    print(f\"Year {year}: {prediction:.2f}\")\n",
    "\n",
    "# Update model comparison\n",
    "models['Improved CNN'] = (mse_cnn, r2_cnn)\n",
    "print(\"\\nUpdated Model Comparison:\")\n",
    "for model_name, (mse_value, r2_value) in models.items():\n",
    "    print(f\"{model_name} - MSE: {mse_value:.2f}, R-squared: {r2_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model for Time Series Prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        pos = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "        dim = tf.range(self.d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "\n",
    "        angle_rates = 1 / \\\n",
    "            tf.pow(10000.0, (2 * (dim // 2)) /\n",
    "                   tf.cast(self.d_model, tf.float32))\n",
    "        angle_rads = pos * angle_rates\n",
    "\n",
    "        pos_encoding = tf.concat([\n",
    "            tf.sin(angle_rads[:, 0::2]),\n",
    "            tf.cos(angle_rads[:, 1::2])\n",
    "        ], axis=-1)\n",
    "\n",
    "        return x + pos_encoding\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(d_model),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training=None):  # Make training parameter optional\n",
    "        attn_output = self.attention(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "# Prepare sequence data for Transformer\n",
    "sequence_length = 5  # Use last 5 years to predict next year\n",
    "d_model = 64  # Embedding dimension\n",
    "\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        sequences.append(X[i:i+seq_length])\n",
    "        targets.append(y[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "\n",
    "# Create sequences from the scaled data\n",
    "X_seq, y_seq = create_sequences(X_scaled.flatten(), y, sequence_length)\n",
    "# Add feature dimension\n",
    "X_seq = X_seq.reshape(X_seq.shape[0], X_seq.shape[1], 1)\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(X_seq) * 0.8)\n",
    "X_seq_train, X_seq_test = X_seq[:train_size], X_seq[train_size:]\n",
    "y_seq_train, y_seq_test = y_seq[:train_size], y_seq[train_size:]\n",
    "\n",
    "# Create Transformer model\n",
    "\n",
    "\n",
    "def create_transformer_model(seq_length, d_model, num_heads=4, ff_dim=128):\n",
    "    inputs = Input(shape=(seq_length, 1))\n",
    "\n",
    "    # Project input to d_model dimensions\n",
    "    x = Dense(d_model)(inputs)\n",
    "\n",
    "    # Add positional encoding\n",
    "    x = PositionalEncoding(seq_length, d_model)(x)\n",
    "\n",
    "    # Transformer blocks\n",
    "    x = TransformerBlock(d_model, num_heads, ff_dim)(x)\n",
    "    x = TransformerBlock(d_model, num_heads, ff_dim)(x)\n",
    "\n",
    "    # Global average pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    # Final dense layers\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create and compile the model\n",
    "transformer_model = create_transformer_model(sequence_length, d_model)\n",
    "transformer_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print(\"Transformer Model Architecture:\")\n",
    "transformer_model.summary()\n",
    "\n",
    "# Train the model\n",
    "if len(X_seq_train) > 0:\n",
    "    history_transformer = transformer_model.fit(\n",
    "        X_seq_train, y_seq_train,\n",
    "        epochs=200,\n",
    "        batch_size=4,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[EarlyStopping(\n",
    "            monitor='val_loss', patience=30, restore_best_weights=True)],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    y_transformer_pred = transformer_model.predict(X_seq_test).flatten()\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse_transformer = mean_squared_error(y_seq_test, y_transformer_pred)\n",
    "    r2_transformer = r2_score(y_seq_test, y_transformer_pred)\n",
    "    print(f'Transformer Mean Squared Error: {mse_transformer}')\n",
    "    print(f'Transformer R-squared: {r2_transformer}')\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot actual data\n",
    "    plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "\n",
    "    # Get corresponding years for test predictions\n",
    "    test_years = years[sequence_length + train_size:]\n",
    "    if len(test_years) == len(y_transformer_pred):\n",
    "        plt.scatter(test_years, y_transformer_pred, color='red',\n",
    "                    s=100, label='Transformer Predictions', zorder=5)\n",
    "\n",
    "    plt.title('Transformer Impact Score vs Graduation Year')\n",
    "    plt.xlabel('Graduation Year')\n",
    "    plt.ylabel('Impact Score')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Not enough data to create sequences for Transformer model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80125dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Linear trend as base\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "base_model = LinearRegression().fit(X_train, y_train)\n",
    "y_base = base_model.predict(X_train)\n",
    "\n",
    "# Step 2: Model residuals with SVR\n",
    "residuals = y_train - y_base\n",
    "\n",
    "# Scale residuals for SVR\n",
    "scaler_y = StandardScaler()\n",
    "scaled_residuals = scaler_y.fit_transform(residuals.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Train SVR on residuals\n",
    "svr_residual = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "svr_residual.fit(X_train, scaled_residuals)\n",
    "\n",
    "# Predict residuals\n",
    "residual_pred = scaler_y.inverse_transform(\n",
    "    svr_residual.predict(X_test).reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "\n",
    "def get_predictions(x):\n",
    "    \"\"\"Get predictions from the base model and residuals.\"\"\"\n",
    "    base_pred = base_model.predict(x)\n",
    "    residuals_pred = scaler_y.inverse_transform(\n",
    "        svr_residual.predict(x).reshape(-1, 1)\n",
    "    ).ravel()\n",
    "    return base_pred + residuals_pred\n",
    "\n",
    "\n",
    "# Step 3: Combined prediction\n",
    "y_pred_hybrid = get_predictions(X_test)\n",
    "\n",
    "# Evaluate the hybrid model\n",
    "mse_hybrid = mean_squared_error(y_test, y_pred_hybrid)\n",
    "r2_hybrid = r2_score(y_test, y_pred_hybrid)\n",
    "print(f'Hybrid Model Mean Squared Error: {mse_hybrid}')\n",
    "print(f'Hybrid Model R-squared: {r2_hybrid}')\n",
    "\n",
    "# Plot the hybrid model results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars using year values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_pred_hybrid, color='purple',\n",
    "            s=50, label='Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Plot hybrid line\n",
    "X_train_years = scaler.inverse_transform(X_train)\n",
    "plt.plot(X_train_years.flatten(), get_predictions(X_train),\n",
    "         color='orange', linewidth=2, label='Base Model Line')\n",
    "plt.title('Hybrid Model Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Add hybrid model to comparison\n",
    "models['Hybrid Model'] = (mse_hybrid, r2_hybrid)\n",
    "# Final model comparison\n",
    "print(\"\\nFinal Model Comparison with Hybrid Model:\")\n",
    "sorted_models = sorted(models.items(), key=lambda x: x[1][0])  # Sort by MSE\n",
    "for model_name, (mse_value, r2_value) in sorted_models:\n",
    "    print(f\"{model_name:20} - MSE: {mse_value:10.2f}, R²: {r2_value:8.4f}\")\n",
    "\n",
    "# Forecast future values with the hybrid model\n",
    "last_year = years.max()  # Find most recent year in data\n",
    "future_years = np.arange(last_year + 1, last_year + 26).reshape(-1, 1)\n",
    "\n",
    "# Scale future years using the SAME scaler used for training\n",
    "future_years_scaled = scaler.transform(future_years)\n",
    "\n",
    "# Hybrid model prediction\n",
    "future_linear = base_model.predict(future_years_scaled)\n",
    "future_residuals = svr_residual.predict(future_years_scaled)\n",
    "# future_predictions = future_linear + future_residuals\n",
    "future_predictions = get_predictions(future_years_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Historical actual data\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Historical Actual')\n",
    "\n",
    "# Historical predictions (from previous plot)\n",
    "plt.scatter(X_test_years.flatten(), y_pred_hybrid, color='purple',\n",
    "            s=50, label='Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Future forecast\n",
    "plt.scatter(future_years, future_predictions, color='red', s=100,\n",
    "            marker='X', label='Forecast', zorder=10)\n",
    "\n",
    "# Trend line extension\n",
    "extended_years = np.vstack([X_train, future_years_scaled])\n",
    "extended_hybrid = get_predictions(extended_years)\n",
    "\n",
    "# Inverse scale years for plotting\n",
    "extended_years_orig = scaler.inverse_transform(extended_years)\n",
    "plt.plot(extended_years_orig, extended_hybrid, 'g--', linewidth=1.5,\n",
    "         label='Forecast Trend')\n",
    "\n",
    "plt.title('Impact Score Forecast (2025-2029)')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(np.arange(1950, 2030, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4378afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Hybrid Model - Single Neuron + SVR with Iterative Training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class NeuralSVRHybrid:\n",
    "    def __init__(self, learning_rate=0.01, svr_C=100, svr_epsilon=0.1, max_iterations=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.svr_C = svr_C\n",
    "        self.svr_epsilon = svr_epsilon\n",
    "        self.max_iterations = max_iterations\n",
    "        self.neural_model = None\n",
    "        self.svr_model = None\n",
    "        self.scaler_y = StandardScaler()\n",
    "        self.history = {'loss': [], 'neural_mse': [],\n",
    "                        'svr_mse': [], 'combined_mse': []}\n",
    "\n",
    "    def _create_neural_model(self, input_shape):\n",
    "        \"\"\"Create a single neuron model\"\"\"\n",
    "        model = Sequential([\n",
    "            Dense(1, input_shape=(input_shape,),\n",
    "                  use_bias=True, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(\n",
    "            learning_rate=self.learning_rate), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X_train, y_train, verbose=1):\n",
    "        \"\"\"Train the hybrid model iteratively\"\"\"\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        # Initialize neural model\n",
    "        self.neural_model = self._create_neural_model(X_train.shape[1])\n",
    "\n",
    "        # Initialize with random predictions\n",
    "        neural_pred = self.neural_model.predict(X_train, verbose=0)\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Step 1: Calculate residuals from current neural network predictions\n",
    "            residuals = y_train.reshape(-1, 1) - neural_pred\n",
    "\n",
    "            # Step 2: Train SVR on residuals\n",
    "            scaled_residuals = self.scaler_y.fit_transform(residuals).ravel()\n",
    "            self.svr_model = SVR(kernel='rbf', C=self.svr_C,\n",
    "                                 epsilon=self.svr_epsilon)\n",
    "            self.svr_model.fit(X_train, scaled_residuals)\n",
    "\n",
    "            # Step 3: Get SVR predictions on residuals\n",
    "            svr_residual_pred = self.scaler_y.inverse_transform(\n",
    "                self.svr_model.predict(X_train).reshape(-1, 1)\n",
    "            ).ravel()\n",
    "\n",
    "            # Step 4: Calculate target for neural network (original target - SVR residual correction)\n",
    "            neural_target = y_train - svr_residual_pred\n",
    "\n",
    "            # Step 5: Train neural network for one epoch\n",
    "            history = self.neural_model.fit(\n",
    "                X_train, neural_target, epochs=1, verbose=0)\n",
    "\n",
    "            # Step 6: Get new neural network predictions\n",
    "            neural_pred = self.neural_model.predict(X_train, verbose=0)\n",
    "\n",
    "            # Step 7: Calculate combined prediction and loss\n",
    "            combined_pred = neural_pred.ravel() + svr_residual_pred\n",
    "            combined_mse = mean_squared_error(y_train, combined_pred)\n",
    "            neural_mse = mean_squared_error(y_train, neural_pred.ravel())\n",
    "            svr_mse = mean_squared_error(residuals.ravel(), svr_residual_pred)\n",
    "\n",
    "            # Store metrics\n",
    "            self.history['loss'].append(history.history['loss'][0])\n",
    "            self.history['neural_mse'].append(neural_mse)\n",
    "            self.history['svr_mse'].append(svr_mse)\n",
    "            self.history['combined_mse'].append(combined_mse)\n",
    "\n",
    "            if verbose and (iteration + 1) % 10 == 0:\n",
    "                print(\n",
    "                    f\"Iteration {iteration + 1}: Combined MSE = {combined_mse:.2f}, Neural MSE = {neural_mse:.2f}, SVR MSE = {svr_mse:.2f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the hybrid model\"\"\"\n",
    "        neural_pred = self.neural_model.predict(X, verbose=0)\n",
    "        svr_residual_pred = self.scaler_y.inverse_transform(\n",
    "            self.svr_model.predict(X).reshape(-1, 1)\n",
    "        ).ravel()\n",
    "        return neural_pred.ravel() + svr_residual_pred\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot the training history\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "        axes[0, 0].plot(self.history['combined_mse'])\n",
    "        axes[0, 0].set_title('Combined Model MSE')\n",
    "        axes[0, 0].set_xlabel('Iteration')\n",
    "        axes[0, 0].set_ylabel('MSE')\n",
    "\n",
    "        axes[0, 1].plot(self.history['neural_mse'])\n",
    "        axes[0, 1].set_title('Neural Network MSE')\n",
    "        axes[0, 1].set_xlabel('Iteration')\n",
    "        axes[0, 1].set_ylabel('MSE')\n",
    "\n",
    "        axes[1, 0].plot(self.history['svr_mse'])\n",
    "        axes[1, 0].set_title('SVR Residual MSE')\n",
    "        axes[1, 0].set_xlabel('Iteration')\n",
    "        axes[1, 0].set_ylabel('MSE')\n",
    "\n",
    "        axes[1, 1].plot(self.history['loss'])\n",
    "        axes[1, 1].set_title('Neural Network Training Loss')\n",
    "        axes[1, 1].set_xlabel('Iteration')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Train the Neural-SVR Hybrid Model\n",
    "print(\"Training Neural-SVR Hybrid Model...\")\n",
    "neural_svr_hybrid = NeuralSVRHybrid(learning_rate=0.13, max_iterations=200)\n",
    "neural_svr_hybrid.fit(X_train, y_train, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_neural_hybrid = neural_svr_hybrid.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_neural_hybrid = mean_squared_error(y_test, y_pred_neural_hybrid)\n",
    "r2_neural_hybrid = r2_score(y_test, y_pred_neural_hybrid)\n",
    "\n",
    "print(f\"\\nNeural-SVR Hybrid Model Results:\")\n",
    "print(f\"Mean Squared Error: {mse_neural_hybrid:.2f}\")\n",
    "print(f\"R-squared: {r2_neural_hybrid:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "neural_svr_hybrid.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Neural-SVR Hybrid Model Results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot actual data\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual Data')\n",
    "\n",
    "# Plot test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_pred_neural_hybrid,\n",
    "            color='red', s=100, label='Neural-SVR Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Plot prediction line for full range\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range)\n",
    "y_range_pred_neural_hybrid = neural_svr_hybrid.predict(X_range_scaled)\n",
    "plt.plot(X_range.flatten(), y_range_pred_neural_hybrid,\n",
    "         color='darkred', linewidth=2, label='Neural-SVR Hybrid Line')\n",
    "\n",
    "# Get component predictions for visualization\n",
    "neural_component = neural_svr_hybrid.neural_model.predict(\n",
    "    X_range_scaled, verbose=0).ravel()\n",
    "svr_component = neural_svr_hybrid.scaler_y.inverse_transform(\n",
    "    neural_svr_hybrid.svr_model.predict(X_range_scaled).reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "plt.plot(X_range.flatten(), neural_component,\n",
    "         color='green', linewidth=1, linestyle='--', alpha=0.7, label='Neural Component')\n",
    "plt.plot(X_range.flatten(), neural_component + svr_component,\n",
    "         color='orange', linewidth=1, linestyle=':', alpha=0.7, label='Neural + SVR Components')\n",
    "\n",
    "plt.title('Neural-SVR Hybrid Model: Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare all models including the new neural hybrid\n",
    "models['Neural-SVR Hybrid'] = (mse_neural_hybrid, r2_neural_hybrid)\n",
    "\n",
    "print(\"\\nFinal Model Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "sorted_models = sorted(models.items(), key=lambda x: x[1][0])  # Sort by MSE\n",
    "for i, (model_name, (mse_value, r2_value)) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model_name:25} - MSE: {mse_value:10.2f}, R²: {r2_value:8.4f}\")\n",
    "\n",
    "# Show improvement over original hybrid\n",
    "original_hybrid_mse = models['Hybrid Model'][0]\n",
    "improvement = ((original_hybrid_mse - mse_neural_hybrid) /\n",
    "               original_hybrid_mse) * 100\n",
    "print(f\"\\nImprovement over Linear-SVR Hybrid: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future Predictions with Neural-SVR Hybrid Model\n",
    "print(\"Generating future predictions with Neural-SVR Hybrid Model...\")\n",
    "\n",
    "# Predict future years\n",
    "last_year = years.max()\n",
    "future_years_neural = np.arange(last_year + 1, last_year + 5).reshape(-1, 1)\n",
    "future_years_neural_scaled = scaler.transform(future_years_neural)\n",
    "\n",
    "# Get hybrid predictions\n",
    "future_predictions_neural_hybrid = neural_svr_hybrid.predict(\n",
    "    future_years_neural_scaled)\n",
    "\n",
    "# Get component predictions for analysis\n",
    "future_neural_component = neural_svr_hybrid.neural_model.predict(\n",
    "    future_years_neural_scaled, verbose=0).ravel()\n",
    "future_svr_component = neural_svr_hybrid.scaler_y.inverse_transform(\n",
    "    neural_svr_hybrid.svr_model.predict(\n",
    "        future_years_neural_scaled).reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "print(\"\\nFuture Predictions (2022-2027):\")\n",
    "print(\"Year\\tNeural\\t\\tSVR\\t\\tCombined\")\n",
    "print(\"-\" * 50)\n",
    "for i, year in enumerate(future_years_neural.flatten()):\n",
    "    if i < 10:  # Show first 10 years\n",
    "        print(\n",
    "            f\"{year}\\t{future_neural_component[i]:8.1f}\\t{future_svr_component[i]:8.1f}\\t{future_predictions_neural_hybrid[i]:8.1f}\")\n",
    "\n",
    "# Visualization of future predictions\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Historical data\n",
    "plt.bar(years, y, color='blue', alpha=0.5,\n",
    "        label='Historical Actual', width=0.8)\n",
    "# Historical test predictions\n",
    "plt.scatter(X_test_years.flatten(), y_pred_neural_hybrid,\n",
    "            color='red', s=80, label='Test Predictions', zorder=5)\n",
    "\n",
    "# Future predictions\n",
    "plt.scatter(future_years_neural.flatten(), future_predictions_neural_hybrid,\n",
    "            color='darkred', s=100, marker='s', label='Future Predictions', zorder=10)\n",
    "\n",
    "# Trend lines\n",
    "all_years_scaled = np.vstack([X_train, future_years_neural_scaled])\n",
    "all_predictions = neural_svr_hybrid.predict(all_years_scaled)\n",
    "all_years_orig = scaler.inverse_transform(all_years_scaled)\n",
    "\n",
    "plt.plot(all_years_orig.flatten(), all_predictions,\n",
    "         'g--', linewidth=2, alpha=0.8, label='Prediction Trend')\n",
    "\n",
    "# Component analysis for future\n",
    "plt.plot(future_years_neural.flatten(), future_neural_component,\n",
    "         'orange', linewidth=1.5, linestyle=':', alpha=0.8, label='Neural Trend')\n",
    "\n",
    "plt.title('Neural-SVR Hybrid Model: Long-term Impact Score Forecast')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(np.arange(1950, 2050, 10), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis of prediction components\n",
    "print(f\"\\nPrediction Analysis:\")\n",
    "print(\n",
    "    f\"Neural component contribution range: {future_neural_component.min():.1f} to {future_neural_component.max():.1f}\")\n",
    "print(\n",
    "    f\"SVR component contribution range: {future_svr_component.min():.1f} to {future_svr_component.max():.1f}\")\n",
    "print(\n",
    "    f\"Total prediction range: {future_predictions_neural_hybrid.min():.1f} to {future_predictions_neural_hybrid.max():.1f}\")\n",
    "\n",
    "# Save predictions to compare with other models\n",
    "predictions_comparison = {\n",
    "    'Year': future_years_neural.flatten(),\n",
    "    'Neural_SVR_Hybrid': future_predictions_neural_hybrid,\n",
    "    'Neural_Component': future_neural_component,\n",
    "    'SVR_Component': future_svr_component\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(predictions_comparison)\n",
    "print(\"\\nFirst 10 years of predictions:\")\n",
    "print(comparison_df.head(10).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + SVR Hybrid Model - Combining Temporal CNN with SVR for Enhanced Prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CNNSVRHybrid:\n",
    "    def __init__(self, cnn_epochs=200, svr_C=100, svr_epsilon=0.1, learning_rate=0.001):\n",
    "        self.cnn_epochs = cnn_epochs\n",
    "        self.svr_C = svr_C\n",
    "        self.svr_epsilon = svr_epsilon\n",
    "        self.learning_rate = learning_rate\n",
    "        self.cnn_model = None\n",
    "        self.svr_model = None\n",
    "        self.feature_extractor = None\n",
    "        self.scaler_features = StandardScaler()\n",
    "        self.scaler_residuals = StandardScaler()\n",
    "        self.history = None\n",
    "\n",
    "    def _create_cnn_model(self, input_shape):\n",
    "        \"\"\"Create CNN model for feature extraction and initial prediction\"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        # Temporal feature extraction layers\n",
    "        x = Conv1D(filters=32, kernel_size=1, activation='relu')(inputs)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv1D(filters=64, kernel_size=1, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv1D(filters=128, kernel_size=1, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "\n",
    "        # Feature extraction branch\n",
    "        features = Flatten()(x)\n",
    "        features = Dense(64, activation='relu', name='features')(features)\n",
    "\n",
    "        # Prediction branch\n",
    "        prediction = Dense(32, activation='relu')(features)\n",
    "        prediction = Dropout(0.3)(prediction)\n",
    "        prediction = Dense(1, name='prediction')(prediction)\n",
    "\n",
    "        # Create two models: full model and feature extractor\n",
    "        full_model = Model(inputs, prediction)\n",
    "        feature_model = Model(inputs, features)\n",
    "\n",
    "        full_model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        return full_model, feature_model\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None, verbose=1):\n",
    "        \"\"\"Train the CNN-SVR hybrid model\"\"\"\n",
    "        # Ensure input is in the right shape for CNN\n",
    "        if len(X_train.shape) == 2:\n",
    "            X_train_cnn = X_train.reshape(\n",
    "                X_train.shape[0], X_train.shape[1], 1)\n",
    "        else:\n",
    "            X_train_cnn = X_train\n",
    "\n",
    "        if X_val is not None and len(X_val.shape) == 2:\n",
    "            X_val_cnn = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "        else:\n",
    "            X_val_cnn = X_val\n",
    "\n",
    "        # Step 1: Train CNN model\n",
    "        print(\"Step 1: Training CNN for feature extraction and initial prediction...\")\n",
    "        self.cnn_model, self.feature_extractor = self._create_cnn_model(\n",
    "            X_train_cnn.shape[1:])\n",
    "\n",
    "        # Set up callbacks\n",
    "        callbacks = [EarlyStopping(\n",
    "            monitor='val_loss', patience=30, restore_best_weights=True)]\n",
    "\n",
    "        # Train CNN\n",
    "        if X_val_cnn is not None:\n",
    "            self.history = self.cnn_model.fit(\n",
    "                X_train_cnn, y_train,\n",
    "                validation_data=(X_val_cnn, y_val),\n",
    "                epochs=self.cnn_epochs,\n",
    "                batch_size=8,\n",
    "                callbacks=callbacks,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        else:\n",
    "            self.history = self.cnn_model.fit(\n",
    "                X_train_cnn, y_train,\n",
    "                validation_split=0.2,\n",
    "                epochs=self.cnn_epochs,\n",
    "                batch_size=8,\n",
    "                callbacks=callbacks,\n",
    "                verbose=verbose\n",
    "            )\n",
    "\n",
    "        # Step 2: Extract features and CNN predictions\n",
    "        print(\"Step 2: Extracting CNN features and computing residuals...\")\n",
    "        cnn_features = self.feature_extractor.predict(X_train_cnn, verbose=0)\n",
    "        cnn_predictions = self.cnn_model.predict(\n",
    "            X_train_cnn, verbose=0).ravel()\n",
    "\n",
    "        # Step 3: Compute residuals\n",
    "        residuals = y_train - cnn_predictions\n",
    "\n",
    "        # Step 4: Combine original features with CNN features\n",
    "        # Flatten original features if needed\n",
    "        if len(X_train.shape) > 2:\n",
    "            X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "        else:\n",
    "            X_train_flat = X_train\n",
    "\n",
    "        combined_features = np.hstack([X_train_flat, cnn_features])\n",
    "\n",
    "        # Scale combined features\n",
    "        combined_features_scaled = self.scaler_features.fit_transform(\n",
    "            combined_features)\n",
    "\n",
    "        # Scale residuals\n",
    "        residuals_scaled = self.scaler_residuals.fit_transform(\n",
    "            residuals.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Step 5: Train SVR on residuals using combined features\n",
    "        print(\"Step 3: Training SVR on residuals using CNN features...\")\n",
    "        self.svr_model = SVR(kernel='rbf', C=self.svr_C,\n",
    "                             epsilon=self.svr_epsilon, gamma='scale')\n",
    "        self.svr_model.fit(combined_features_scaled, residuals_scaled)\n",
    "\n",
    "        print(\"CNN-SVR Hybrid training completed!\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Make predictions using the CNN-SVR hybrid model\"\"\"\n",
    "        # Ensure input is in the right shape for CNN\n",
    "        if len(X_test.shape) == 2:\n",
    "            X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        else:\n",
    "            X_test_cnn = X_test\n",
    "\n",
    "        # Get CNN predictions and features\n",
    "        cnn_predictions = self.cnn_model.predict(X_test_cnn, verbose=0).ravel()\n",
    "        cnn_features = self.feature_extractor.predict(X_test_cnn, verbose=0)\n",
    "\n",
    "        # Combine original features with CNN features\n",
    "        if len(X_test.shape) > 2:\n",
    "            X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "        else:\n",
    "            X_test_flat = X_test\n",
    "\n",
    "        combined_features = np.hstack([X_test_flat, cnn_features])\n",
    "        combined_features_scaled = self.scaler_features.transform(\n",
    "            combined_features)\n",
    "\n",
    "        # Get SVR residual predictions\n",
    "        svr_residuals_scaled = self.svr_model.predict(combined_features_scaled)\n",
    "        svr_residuals = self.scaler_residuals.inverse_transform(\n",
    "            svr_residuals_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Combine CNN predictions with SVR residual corrections\n",
    "        final_predictions = cnn_predictions + svr_residuals\n",
    "\n",
    "        return final_predictions\n",
    "\n",
    "    def get_component_predictions(self, X_test):\n",
    "        \"\"\"Get individual component predictions for analysis\"\"\"\n",
    "        if len(X_test.shape) == 2:\n",
    "            X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "        else:\n",
    "            X_test_cnn = X_test\n",
    "\n",
    "        # CNN component\n",
    "        cnn_predictions = self.cnn_model.predict(X_test_cnn, verbose=0).ravel()\n",
    "        cnn_features = self.feature_extractor.predict(X_test_cnn, verbose=0)\n",
    "\n",
    "        # SVR component\n",
    "        if len(X_test.shape) > 2:\n",
    "            X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "        else:\n",
    "            X_test_flat = X_test\n",
    "\n",
    "        combined_features = np.hstack([X_test_flat, cnn_features])\n",
    "        combined_features_scaled = self.scaler_features.transform(\n",
    "            combined_features)\n",
    "        svr_residuals_scaled = self.svr_model.predict(combined_features_scaled)\n",
    "        svr_residuals = self.scaler_residuals.inverse_transform(\n",
    "            svr_residuals_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "        return cnn_predictions, svr_residuals\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot CNN training history\"\"\"\n",
    "        if self.history is None:\n",
    "            print(\"No training history available\")\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # Loss plot\n",
    "        axes[0].plot(self.history.history['loss'], label='Training Loss')\n",
    "        axes[0].plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        axes[0].set_title('CNN Training Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # MAE plot\n",
    "        axes[1].plot(self.history.history['mae'], label='Training MAE')\n",
    "        axes[1].plot(self.history.history['val_mae'], label='Validation MAE')\n",
    "        axes[1].set_title('CNN Training MAE')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('MAE')\n",
    "        axes[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Train the CNN-SVR Hybrid Model\n",
    "print(\"Training CNN-SVR Hybrid Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use the same data preparation as other models\n",
    "X_cnn_svr = X_scaled.reshape(-1, 1, 1)\n",
    "y_cnn_svr = y\n",
    "\n",
    "# Use the same train/test split\n",
    "X_cnn_svr_train = X_cnn_svr[:len_data//10*9]\n",
    "X_cnn_svr_test = X_cnn_svr[len_data//10*9:]\n",
    "y_cnn_svr_train = y_cnn_svr[:len_data//10*9]\n",
    "y_cnn_svr_test = y_cnn_svr[len_data//10*9:]\n",
    "\n",
    "# Create and train the hybrid model\n",
    "cnn_svr_hybrid = CNNSVRHybrid(\n",
    "    cnn_epochs=300,\n",
    "    svr_C=100,\n",
    "    svr_epsilon=1.1,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "cnn_svr_hybrid.fit(X_cnn_svr_train, y_cnn_svr_train, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cnn_svr = cnn_svr_hybrid.predict(X_cnn_svr_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_cnn_svr = mean_squared_error(y_cnn_svr_test, y_pred_cnn_svr)\n",
    "r2_cnn_svr = r2_score(y_cnn_svr_test, y_pred_cnn_svr)\n",
    "\n",
    "print(f\"\\nCNN-SVR Hybrid Model Results:\")\n",
    "print(f\"Mean Squared Error: {mse_cnn_svr:.2f}\")\n",
    "print(f\"R-squared: {r2_cnn_svr:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "cnn_svr_hybrid.plot_training_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381198c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CNN-SVR Hybrid Model Results\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Create subplot layout\n",
    "gs = plt.GridSpec(2, 2, height_ratios=[2, 1], hspace=0.3)\n",
    "\n",
    "# Main prediction plot\n",
    "ax1 = plt.subplot(gs[0, :])\n",
    "\n",
    "# Plot actual data\n",
    "ax1.bar(years, y, color='blue', alpha=0.5, label='Actual Data', width=0.8)\n",
    "\n",
    "# Plot test predictions\n",
    "X_test_years = scaler.inverse_transform(X_cnn_svr_test.reshape(-1, 1))\n",
    "ax1.scatter(X_test_years.flatten(), y_pred_cnn_svr,\n",
    "            color='red', s=100, label='CNN-SVR Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Plot prediction line for full range\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range).reshape(-1, 1, 1)\n",
    "y_range_pred_cnn_svr = cnn_svr_hybrid.predict(X_range_scaled)\n",
    "ax1.plot(X_range.flatten(), y_range_pred_cnn_svr,\n",
    "         color='darkred', linewidth=2, label='CNN-SVR Hybrid Line')\n",
    "\n",
    "# Get component predictions for visualization\n",
    "cnn_component, svr_component = cnn_svr_hybrid.get_component_predictions(\n",
    "    X_range_scaled)\n",
    "\n",
    "ax1.plot(X_range.flatten(), cnn_component,\n",
    "         color='green', linewidth=1.5, linestyle='--', alpha=0.8, label='CNN Component')\n",
    "ax1.plot(X_range.flatten(), svr_component,\n",
    "         color='orange', linewidth=1.5, linestyle=':', alpha=0.8, label='SVR Residual Component')\n",
    "\n",
    "ax1.set_title('CNN-SVR Hybrid Model: Impact Score vs Graduation Year',\n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Graduation Year')\n",
    "ax1.set_ylabel('Impact Score')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Component analysis subplot\n",
    "ax2 = plt.subplot(gs[1, 0])\n",
    "test_cnn_comp, test_svr_comp = cnn_svr_hybrid.get_component_predictions(\n",
    "    X_cnn_svr_test)\n",
    "ax2.bar(['CNN\\nComponent', 'SVR\\nComponent', 'Combined'],\n",
    "        [np.mean(test_cnn_comp), np.mean(\n",
    "            test_svr_comp), np.mean(y_pred_cnn_svr)],\n",
    "        color=['green', 'orange', 'red'], alpha=0.7)\n",
    "ax2.set_title('Average Component Contributions')\n",
    "ax2.set_ylabel('Average Value')\n",
    "\n",
    "# Prediction accuracy subplot\n",
    "ax3 = plt.subplot(gs[1, 1])\n",
    "residuals_cnn_svr = y_cnn_svr_test - y_pred_cnn_svr\n",
    "ax3.hist(residuals_cnn_svr, bins=10, alpha=0.7, color='purple')\n",
    "ax3.set_title('Prediction Residuals Distribution')\n",
    "ax3.set_xlabel('Residual')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.axvline(0, color='red', linestyle='--', alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add CNN-SVR Hybrid to model comparison\n",
    "models['CNN-SVR Hybrid'] = (mse_cnn_svr, r2_cnn_svr)\n",
    "\n",
    "print(\"\\nUpdated Model Comparison with CNN-SVR Hybrid:\")\n",
    "print(\"=\" * 65)\n",
    "sorted_models = sorted(models.items(), key=lambda x: x[1][0])  # Sort by MSE\n",
    "for i, (model_name, (mse_value, r2_value)) in enumerate(sorted_models, 1):\n",
    "    print(f\"{i}. {model_name:25} - MSE: {mse_value:10.2f}, R²: {r2_value:8.4f}\")\n",
    "\n",
    "# Show improvement analysis\n",
    "standalone_cnn_mse = models['Improved CNN'][0]\n",
    "standalone_svr_mse = models['SVR'][0]\n",
    "improvement_over_cnn = (\n",
    "    (standalone_cnn_mse - mse_cnn_svr) / standalone_cnn_mse) * 100\n",
    "improvement_over_svr = (\n",
    "    (standalone_svr_mse - mse_cnn_svr) / standalone_svr_mse) * 100\n",
    "\n",
    "print(f\"\\nHybrid Model Performance Analysis:\")\n",
    "print(f\"Improvement over standalone CNN: {improvement_over_cnn:.2f}%\")\n",
    "print(f\"Improvement over standalone SVR: {improvement_over_svr:.2f}%\")\n",
    "\n",
    "# Detailed component analysis\n",
    "print(f\"\\nComponent Analysis on Test Set:\")\n",
    "print(\n",
    "    f\"CNN component range: {test_cnn_comp.min():.1f} to {test_cnn_comp.max():.1f}\")\n",
    "print(\n",
    "    f\"SVR component range: {test_svr_comp.min():.1f} to {test_svr_comp.max():.1f}\")\n",
    "print(\n",
    "    f\"CNN component contribution: {np.mean(np.abs(test_cnn_comp)):.1f} (avg absolute)\")\n",
    "print(\n",
    "    f\"SVR component contribution: {np.mean(np.abs(test_svr_comp)):.1f} (avg absolute)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc01b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict future values with CNN-SVR Hybrid Model\n",
    "print(\"Generating future predictions with CNN-SVR Hybrid Model...\")\n",
    "# Predict future years\n",
    "last_year = years.max()\n",
    "future_years_cnn_svr = np.arange(last_year + 1, last_year + 26).reshape(-1, 1)\n",
    "future_years_cnn_svr_scaled = scaler.transform(\n",
    "    future_years_cnn_svr).reshape(-1, 1, 1)\n",
    "# Get hybrid predictions\n",
    "future_predictions_cnn_svr = cnn_svr_hybrid.predict(\n",
    "    future_years_cnn_svr_scaled)\n",
    "# Get component predictions for analysis\n",
    "future_cnn_component, future_svr_component = cnn_svr_hybrid.get_component_predictions(\n",
    "    future_years_cnn_svr_scaled)\n",
    "print(\"\\nFuture Predictions (2022-2046):\")\n",
    "print(\"Year\\tCNN\\t\\tSVR\\t\\tCombined\")\n",
    "print(\"-\" * 50)\n",
    "for i, year in enumerate(future_years_cnn_svr.flatten()):\n",
    "    if i < 10:  # Show first 10 years\n",
    "        print(\n",
    "            f\"{year}\\t{future_cnn_component[i]:8.1f}\\t{future_svr_component[i]:8.1f}\\t{future_predictions_cnn_svr[i]:8.1f}\")\n",
    "# Visualization of future predictions\n",
    "plt.figure(figsize=(14, 8))\n",
    "# Historical data\n",
    "plt.bar(years, y, color='blue', alpha=0.5,\n",
    "        label='Historical Actual', width=0.8)\n",
    "# Historical test predictions\n",
    "plt.scatter(X_test_years.flatten(), y_pred_cnn_svr,\n",
    "            color='red', s=80, label='Test Predictions', zorder=5)\n",
    "# Future predictions\n",
    "plt.scatter(future_years_cnn_svr.flatten(), future_predictions_cnn_svr,\n",
    "            color='darkred', s=100, marker='s', label='Future Predictions', zorder=10)\n",
    "# Trend lines\n",
    "all_years_cnn_svr_scaled = np.vstack(\n",
    "    [X_cnn_svr_train, future_years_cnn_svr_scaled])\n",
    "all_predictions_cnn_svr = cnn_svr_hybrid.predict(all_years_cnn_svr_scaled)\n",
    "all_years_cnn_svr_orig = scaler.inverse_transform(\n",
    "    all_years_cnn_svr_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "plt.plot(all_years_cnn_svr_orig, all_predictions_cnn_svr,\n",
    "         'g--', linewidth=2, alpha=0.8, label='Prediction Trend')\n",
    "# Component analysis for future\n",
    "plt.plot(future_years_cnn_svr.flatten(), future_cnn_component,\n",
    "         'orange', linewidth=1.5, linestyle=':', alpha=0.8, label='CNN Component')\n",
    "plt.plot(future_years_cnn_svr.flatten(), future_svr_component,\n",
    "         'purple', linewidth=1.5, linestyle='--', alpha=0.8, label='SVR Component')\n",
    "plt.title('CNN-SVR Hybrid Model: Long-term Impact Score Forecast')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(np.arange(1950, 2050, 10), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
