{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cleandata import add_impact_score, get_data, plot_grouped_impact_scores, remove_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n",
    "df = add_impact_score(df)\n",
    "df = remove_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eba4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_impact_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's reload the data to see what we're working with\n",
    "df = get_data()\n",
    "df = add_impact_score(df)\n",
    "df = remove_outliers(df)\n",
    "\n",
    "# Check the unique values in graduation year column\n",
    "# print(\"Unique graduation years:\")\n",
    "# print(df['años de graduación'].value_counts())\n",
    "# print(f\"\\nTotal rows before filtering: {len(df)}\")\n",
    "\n",
    "# Check how many rows would be removed\n",
    "# rows_to_remove = df[(df['años de graduación'] == 2022) | (df['años de graduación'] == 'Sin dato')]\n",
    "# print(f\"Rows that would be removed: {len(rows_to_remove)}\")\n",
    "\n",
    "# Apply the filter\n",
    "df_filtered = df[~((df['años de graduación'] == '2022') |\n",
    "                   (df['años de graduación'] == 'Sin dato'))]\n",
    "print(f\"Rows remaining after filtering: {len(df_filtered)}\")\n",
    "\n",
    "# Plot with the filtered data\n",
    "if len(df_filtered) > 0:\n",
    "    plot_grouped_impact_scores(df_filtered)\n",
    "else:\n",
    "    print(\"No data remaining after filtering. Consider adjusting the filter criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba74904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1, len(pd.read_csv('80QS.csv')))\n",
    "print(2, len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.unique(df_filtered['años de graduación'], return_counts=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=X, y=Y, palette='viridis')\n",
    "plt.title('Graduation Year Distribution')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graduation_year_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a83b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data for regression\n",
    "grouped = df_filtered.groupby('años de graduación')[\n",
    "    'impact_score'].sum().reset_index()\n",
    "X = grouped['años de graduación'].values.reshape(-1, 1)\n",
    "y = grouped['impact_score'].values\n",
    "# Convert years to numeric values\n",
    "X = X.astype(float)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# Create and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "# Plot the regression results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars\n",
    "plt.bar(X.flatten(), y, color='blue', alpha=0.5, label='Actual')\n",
    "# Plot regression line\n",
    "X_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "y_range_pred = model.predict(X_range)\n",
    "plt.plot(X_range.flatten(), y_range_pred, color='red',\n",
    "         linewidth=2, label='Regression Line')\n",
    "# Plot test predictions\n",
    "plt.scatter(X_test.flatten(), y_pred, color='orange',\n",
    "            s=50, label='Test Predictions', zorder=5)\n",
    "plt.title('Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('impact_score_vs_graduation_year.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA model\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Prepare the data for ARIMA\n",
    "grouped = df_filtered.groupby('años de graduación')[\n",
    "    'impact_score'].sum().reset_index()\n",
    "# Convert years to datetime format\n",
    "grouped['años de graduación'] = pd.to_datetime(\n",
    "    grouped['años de graduación'], format='%Y', errors='coerce')\n",
    "# Set the index to the graduation year\n",
    "grouped.set_index('años de graduación', inplace=True)\n",
    "# Ensure the index is sorted\n",
    "grouped.sort_index(inplace=True)\n",
    "print(\"Grouped Data for ARIMA:\")\n",
    "print(grouped.head())\n",
    "# Fit the ARIMA model\n",
    "model = ARIMA(grouped['impact_score'], order=(0, 1, 5))\n",
    "model_fit = model.fit()\n",
    "# Make predictions\n",
    "# for each year in the next 5 years\n",
    "forecast = model_fit.forecast(steps=5)\n",
    "# Print the forecasted values\n",
    "print(\"ARIMA Forecast for the next 5 years:\")\n",
    "print(forecast)\n",
    "# Create future dates for forecasting\n",
    "last_date = grouped.index[-1]\n",
    "future_dates = pd.date_range(\n",
    "    start=last_date + pd.DateOffset(years=1), periods=5, freq='YE')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plot historical data using the index (which is now the datetime)\n",
    "plt.plot(grouped.index, grouped['impact_score'],\n",
    "         label='Historical Data', color='blue', marker='o')\n",
    "\n",
    "# Plot forecast\n",
    "plt.plot(future_dates, forecast,\n",
    "         label='ARIMA Forecast', color='red', marker='s', linestyle='--')\n",
    "\n",
    "plt.title('ARIMA Forecast of Impact Score')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('arima_forecast_impact_score.png')\n",
    "plt.show()\n",
    "\n",
    "# Print the forecast with corresponding years\n",
    "print(\"\\nDetailed Forecast:\")\n",
    "for i, (date, value) in enumerate(zip(future_dates, forecast)):\n",
    "    print(f\"Year {date.year}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35548707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regression (SVR)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare the data for SVR - use year values instead of datetime\n",
    "grouped_reset = grouped.reset_index()\n",
    "grouped_reset['year'] = grouped_reset['años de graduación'].dt.year\n",
    "\n",
    "X = grouped_reset['year'].values.reshape(-1, 1)\n",
    "y = grouped_reset['impact_score'].values\n",
    "\n",
    "# Scale the features for better SVR performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_scaled, y, test_size=0.2, random_state=42)\n",
    "len_data = len(X_scaled)\n",
    "X_train, X_test, y_train, y_test = X_scaled[:int(\n",
    "    len_data*0.9)], X_scaled[int(len_data*0.9):], y[:int(len_data*0.9)], y[int(len_data*0.9):]\n",
    "\n",
    "# Create and fit the SVR model\n",
    "svr_model = SVR(kernel='rbf', C=10000000, gamma='scale', epsilon=0.1)\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_svr_pred = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVR model\n",
    "mse_svr = mean_squared_error(y_test, y_svr_pred)\n",
    "r2_svr = r2_score(y_test, y_svr_pred)\n",
    "print(f'SVR Mean Squared Error: {mse_svr}')\n",
    "print(f'SVR R-squared: {r2_svr}')\n",
    "\n",
    "# Plot the SVR results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot actual data as bars using year values\n",
    "years = grouped_reset['year'].values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_svr_pred, color='orange',\n",
    "            s=50, label='SVR Predictions', zorder=5)\n",
    "\n",
    "# Plot SVR line\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range)\n",
    "y_svr_range_pred = svr_model.predict(X_range_scaled)\n",
    "plt.plot(X_range.flatten(), y_svr_range_pred,\n",
    "         color='green', linewidth=2, label='SVR Line')\n",
    "\n",
    "plt.title('SVR Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict 5 more years into the future\n",
    "future_years = np.array([2022, 2023, 2024, 2025, 2026,\n",
    "                        2027, 2028, 2029, 2030]).reshape(-1, 1)\n",
    "future_years_scaled = scaler.transform(future_years)\n",
    "future_predictions = svr_model.predict(future_years_scaled)\n",
    "\n",
    "print(\"\\nSVR Forecast for the next 5 years:\")\n",
    "for year, prediction in zip(future_years.flatten(), future_predictions):\n",
    "    print(f\"Year {year}: {prediction:.2f}\")\n",
    "\n",
    "# Plot with future predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Historical Data')\n",
    "plt.scatter(future_years.flatten(), future_predictions,\n",
    "            color='red', s=100, label='Future Predictions', marker='s')\n",
    "plt.plot(X_range.flatten(), y_svr_range_pred,\n",
    "         color='green', linewidth=2, label='SVR Line')\n",
    "\n",
    "plt.title('SVR Impact Score Forecast')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=1000)\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "# Evaluate the Random Forest model\n",
    "mse_rf = mean_squared_error(y_test, y_rf_pred)\n",
    "r2_rf = r2_score(y_test, y_rf_pred)\n",
    "print(f'Random Forest Mean Squared Error: {mse_rf}')\n",
    "print(f'Random Forest R-squared: {r2_rf}')\n",
    "# Plot the Random Forest results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars using year values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_rf_pred, color='orange',\n",
    "            s=50, label='RF Predictions', zorder=5)\n",
    "# Plot Random Forest line\n",
    "X_range = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_scaled = scaler.transform(X_range)\n",
    "y_rf_range_pred = rf_model.predict(X_range_scaled)\n",
    "plt.plot(X_range.flatten(), y_rf_range_pred,\n",
    "         color='purple', linewidth=2, label='RF Line')\n",
    "plt.title('Random Forest Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Compare models\n",
    "models = {\n",
    "    'Linear Regression': (mse, r2),\n",
    "    'SVR': (mse_svr, r2_svr),\n",
    "    'Random Forest': (mse_rf, r2_rf)\n",
    "}\n",
    "print(\"\\nModel Comparison:\")\n",
    "for model_name, (mse_value, r2_value) in models.items():\n",
    "    print(f\"{model_name} - Mean Squared Error: {mse_value:.2f}, R-squared: {r2_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning - Improved CNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Prepare the data for CNN with better preprocessing\n",
    "# Use the scaled data from SVR\n",
    "X_cnn = X_scaled.reshape(-1, 1, 1)  # Reshape for CNN (samples, timesteps, features)\n",
    "y_cnn = y\n",
    "\n",
    "# Use the same train/test split as other models for fair comparison\n",
    "X_cnn_train = X_cnn[:len_data//10*9]\n",
    "X_cnn_test = X_cnn[len_data//10*9:]\n",
    "y_cnn_train = y_cnn[:len_data//10*9]\n",
    "y_cnn_test = y_cnn[len_data//10*9:]\n",
    "\n",
    "# Create an improved CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(1, 1)),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(filters=64, kernel_size=1, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile with better parameters\n",
    "cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit the model with validation split\n",
    "history = cnn_model.fit(\n",
    "    X_cnn_train, y_cnn_train,\n",
    "    epochs=1000,\n",
    "    batch_size=8,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_cnn_pred = cnn_model.predict(X_cnn_test).flatten()\n",
    "\n",
    "# Evaluate the CNN model\n",
    "mse_cnn = mean_squared_error(y_cnn_test, y_cnn_pred)\n",
    "r2_cnn = r2_score(y_cnn_test, y_cnn_pred)\n",
    "print(f'Improved CNN Mean Squared Error: {mse_cnn}')\n",
    "print(f'Improved CNN R-squared: {r2_cnn}')\n",
    "\n",
    "# Plot the CNN results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot actual data as bars\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "\n",
    "# Get corresponding years for test predictions\n",
    "X_cnn_test_years = scaler.inverse_transform(X_cnn_test.reshape(-1, 1))\n",
    "plt.scatter(X_cnn_test_years.flatten(), y_cnn_pred, color='orange',\n",
    "            s=100, label='CNN Predictions', zorder=5)\n",
    "\n",
    "# Plot CNN line for the full range\n",
    "X_range_cnn = np.linspace(years.min(), years.max(), 100).reshape(-1, 1)\n",
    "X_range_cnn_scaled = scaler.transform(X_range_cnn).reshape(-1, 1, 1)\n",
    "y_cnn_range_pred = cnn_model.predict(X_range_cnn_scaled).flatten()\n",
    "plt.plot(X_range_cnn.flatten(), y_cnn_range_pred,\n",
    "         color='cyan', linewidth=2, label='CNN Line')\n",
    "\n",
    "plt.title('Improved CNN Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Predict future values\n",
    "future_years_cnn_scaled = scaler.transform(future_years).reshape(-1, 1, 1)\n",
    "future_cnn_predictions = cnn_model.predict(future_years_cnn_scaled).flatten()\n",
    "\n",
    "print(\"\\nCNN Forecast for future years:\")\n",
    "for year, prediction in zip(future_years.flatten(), future_cnn_predictions):\n",
    "    print(f\"Year {year}: {prediction:.2f}\")\n",
    "\n",
    "# Update model comparison\n",
    "models['Improved CNN'] = (mse_cnn, r2_cnn)\n",
    "print(\"\\nUpdated Model Comparison:\")\n",
    "for model_name, (mse_value, r2_value) in models.items():\n",
    "    print(f\"{model_name} - MSE: {mse_value:.2f}, R-squared: {r2_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871b277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Transformer Model for Time Series Prediction\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        pos = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "        dim = tf.range(self.d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "        \n",
    "        angle_rates = 1 / tf.pow(10000.0, (2 * (dim // 2)) / tf.cast(self.d_model, tf.float32))\n",
    "        angle_rads = pos * angle_rates\n",
    "        \n",
    "        pos_encoding = tf.concat([\n",
    "            tf.sin(angle_rads[:, 0::2]),\n",
    "            tf.cos(angle_rads[:, 1::2])\n",
    "        ], axis=-1)\n",
    "        \n",
    "        return x + pos_encoding\n",
    "\n",
    "class SimpleTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(SimpleTransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=d_model//num_heads,  # Smaller key dimension\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "            Dropout(dropout),\n",
    "            Dense(d_model, kernel_regularizer=l2(0.01)),\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Self-attention with residual connection\n",
    "        attn_output = self.attention(inputs, inputs, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        # Feed forward with residual connection\n",
    "        ffn_output = self.ffn(out1, training=training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "# Reduce sequence length for small dataset\n",
    "sequence_length = 3  # Reduced from 5 to get more training samples\n",
    "d_model = 32  # Reduced from 64 to prevent overfitting\n",
    "\n",
    "def create_sequences(X, y, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(X) - seq_length):\n",
    "        sequences.append(X[i:i+seq_length])\n",
    "        targets.append(y[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Create sequences with additional features\n",
    "X_seq, y_seq = create_sequences(X_scaled.flatten(), y, sequence_length)\n",
    "\n",
    "# Add more features: year differences and moving averages\n",
    "X_enhanced = []\n",
    "for i in range(len(X_seq)):\n",
    "    seq = X_seq[i]\n",
    "    # Calculate differences and moving average\n",
    "    diffs = np.diff(seq, prepend=seq[0])\n",
    "    moving_avg = np.convolve(seq, np.ones(len(seq))/len(seq), mode='same')\n",
    "    \n",
    "    # Stack features: [original, differences, moving_avg]\n",
    "    enhanced_seq = np.column_stack([seq, diffs, moving_avg])\n",
    "    X_enhanced.append(enhanced_seq)\n",
    "\n",
    "X_seq = np.array(X_enhanced)\n",
    "print(f\"Enhanced sequence shape: {X_seq.shape}\")\n",
    "\n",
    "# Split data with more training samples\n",
    "train_size = max(1, int(len(X_seq) * 0.85))  # Use 85% for training\n",
    "X_seq_train, X_seq_test = X_seq[:train_size], X_seq[train_size:]\n",
    "y_seq_train, y_seq_test = y_seq[:train_size], y_seq[train_size:]\n",
    "\n",
    "print(f\"Training sequences: {len(X_seq_train)}, Test sequences: {len(X_seq_test)}\")\n",
    "\n",
    "# Create a simpler, more appropriate Transformer model\n",
    "def create_improved_transformer_model(seq_length, feature_dim, d_model=32, num_heads=2, ff_dim=64):\n",
    "    inputs = Input(shape=(seq_length, feature_dim))\n",
    "    \n",
    "    # Smaller embedding projection\n",
    "    x = Dense(d_model, kernel_regularizer=l2(0.01))(inputs)\n",
    "    \n",
    "    # Add positional encoding\n",
    "    x = PositionalEncoding(seq_length, d_model)(x)\n",
    "    \n",
    "    # Single transformer block (reduced complexity)\n",
    "    x = SimpleTransformerBlock(d_model, num_heads, ff_dim, dropout=0.2)(x)\n",
    "    \n",
    "    # Use LSTM as well for sequence understanding\n",
    "    x = tf.keras.layers.LSTM(32, return_sequences=False, dropout=0.2)(x)\n",
    "    \n",
    "    # Simpler output layers\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "if len(X_seq_train) > 0:\n",
    "    # Create and compile the improved model\n",
    "    transformer_model = create_improved_transformer_model(\n",
    "        sequence_length, \n",
    "        X_seq.shape[2],  # Number of features\n",
    "        d_model=d_model\n",
    "    )\n",
    "    \n",
    "    # Use a lower learning rate and different optimizer\n",
    "    transformer_model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.01),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    print(\"Improved Transformer Model Architecture:\")\n",
    "    transformer_model.summary()\n",
    "\n",
    "    # Enhanced callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, min_delta=1e-4),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_transformer.h5', save_best_only=True, monitor='val_loss')\n",
    "    ]\n",
    "    \n",
    "    # Train with reduced epochs and smaller batch size\n",
    "    history_transformer = transformer_model.fit(\n",
    "        X_seq_train, y_seq_train,\n",
    "        epochs=100,  # Reduced from 500\n",
    "        batch_size=2,  # Smaller batch size\n",
    "        validation_split=0.15,  # Smaller validation split\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    y_transformer_pred = transformer_model.predict(X_seq_test).flatten()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mse_transformer = mean_squared_error(y_seq_test, y_transformer_pred)\n",
    "    r2_transformer = r2_score(y_seq_test, y_transformer_pred)\n",
    "    print(f'Improved Transformer Mean Squared Error: {mse_transformer:.2f}')\n",
    "    print(f'Improved Transformer R-squared: {r2_transformer:.4f}')\n",
    "    \n",
    "    # Plot results with better visualization\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Model predictions vs actual\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.bar(years, y, color='blue', alpha=0.5, label='Actual', width=0.8)\n",
    "    \n",
    "    # Get corresponding years for test predictions\n",
    "    test_years = years[sequence_length + train_size:]\n",
    "    if len(test_years) == len(y_transformer_pred):\n",
    "        plt.scatter(test_years, y_transformer_pred, color='red',\n",
    "                   s=100, label='Transformer Predictions', zorder=5, marker='D')\n",
    "    \n",
    "    plt.title('Transformer: Predictions vs Actual')\n",
    "    plt.xlabel('Graduation Year')\n",
    "    plt.ylabel('Impact Score')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot 2: Prediction accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if len(y_seq_test) > 0:\n",
    "        plt.scatter(y_seq_test, y_transformer_pred, alpha=0.7, color='green')\n",
    "        plt.plot([y_seq_test.min(), y_seq_test.max()], \n",
    "                 [y_seq_test.min(), y_seq_test.max()], 'r--', lw=2)\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title('Prediction Accuracy')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Training history\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history_transformer.history['loss'], label='Training Loss', linewidth=2)\n",
    "    if 'val_loss' in history_transformer.history:\n",
    "        plt.plot(history_transformer.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Predict future values with the enhanced features\n",
    "    if len(X_scaled) >= sequence_length:\n",
    "        last_sequence_simple = X_scaled[-sequence_length:].flatten()\n",
    "        \n",
    "        future_transformer_predictions = []\n",
    "        current_sequence = last_sequence_simple.copy()\n",
    "        \n",
    "        for i in range(5):  # Predict 5 years ahead\n",
    "            # Create enhanced features for prediction\n",
    "            diffs = np.diff(current_sequence, prepend=current_sequence[0])\n",
    "            moving_avg = np.convolve(current_sequence, np.ones(len(current_sequence))/len(current_sequence), mode='same')\n",
    "            enhanced_seq = np.column_stack([current_sequence, diffs, moving_avg])\n",
    "            enhanced_seq = enhanced_seq.reshape(1, sequence_length, 3)\n",
    "            \n",
    "            next_pred = transformer_model.predict(enhanced_seq, verbose=0)[0, 0]\n",
    "            future_transformer_predictions.append(next_pred)\n",
    "            \n",
    "            # Update sequence: remove first, add predicted (scaled)\n",
    "            next_year_scaled = scaler.transform([[years.max() + i + 1]])[0, 0]\n",
    "            current_sequence = np.roll(current_sequence, -1)\n",
    "            current_sequence[-1] = next_year_scaled\n",
    "    \n",
    "        print(\"\\nImproved Transformer Forecast:\")\n",
    "        for i, prediction in enumerate(future_transformer_predictions):\n",
    "            print(f\"Year {2022 + i}: {prediction:.2f}\")\n",
    "    \n",
    "        # Add to model comparison\n",
    "        models['Improved Transformer'] = (mse_transformer, r2_transformer)\n",
    "        \n",
    "        # Final model comparison\n",
    "        print(\"\\nFinal Model Comparison:\")\n",
    "        print(\"-\" * 60)\n",
    "        sorted_models = sorted(models.items(), key=lambda x: x[1][0])  # Sort by MSE\n",
    "        for model_name, (mse_value, r2_value) in sorted_models:\n",
    "            print(f\"{model_name:20} - MSE: {mse_value:10.2f}, R²: {r2_value:8.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Not enough data to create sequences for Transformer model\")\n",
    "    \n",
    "    # Alternative: Simple LSTM model for small datasets\n",
    "    print(\"\\nTrying simpler LSTM approach instead...\")\n",
    "    \n",
    "    # Create simple sequences for LSTM\n",
    "    X_simple, y_simple = create_sequences(X_scaled.flatten(), y, 2)  # Even shorter sequences\n",
    "    X_simple = X_simple.reshape(X_simple.shape[0], X_simple.shape[1], 1)\n",
    "    \n",
    "    if len(X_simple) > 5:\n",
    "        train_size_simple = max(1, int(len(X_simple) * 0.8))\n",
    "        X_train_simple = X_simple[:train_size_simple]\n",
    "        X_test_simple = X_simple[train_size_simple:]\n",
    "        y_train_simple = y_simple[:train_size_simple]\n",
    "        y_test_simple = y_simple[train_size_simple:]\n",
    "        \n",
    "        # Simple LSTM model\n",
    "        simple_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(16, return_sequences=False, dropout=0.2),\n",
    "            tf.keras.layers.Dense(8, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        \n",
    "        simple_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "        simple_model.fit(X_train_simple, y_train_simple, epochs=50, verbose=0)\n",
    "        \n",
    "        y_simple_pred = simple_model.predict(X_test_simple).flatten()\n",
    "        mse_simple = mean_squared_error(y_test_simple, y_simple_pred)\n",
    "        r2_simple = r2_score(y_test_simple, y_simple_pred)\n",
    "        \n",
    "        print(f\"Simple LSTM MSE: {mse_simple:.2f}, R²: {r2_simple:.4f}\")\n",
    "        models['Simple LSTM'] = (mse_simple, r2_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80125dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Linear trend as base\n",
    "from sklearn.linear_model import LinearRegression\n",
    "base_model = LinearRegression().fit(X_train, y_train)\n",
    "y_base = base_model.predict(X_train)\n",
    "\n",
    "# Step 2: Model residuals with SVR\n",
    "residuals = y_train - y_base\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale residuals for SVR\n",
    "scaler_y = StandardScaler()\n",
    "scaled_residuals = scaler_y.fit_transform(residuals.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Train SVR on residuals\n",
    "svr_residual = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "svr_residual.fit(X_train, scaled_residuals)\n",
    "\n",
    "# Predict residuals\n",
    "residual_pred = scaler_y.inverse_transform(\n",
    "    svr_residual.predict(X_test).reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "def get_predictions(x):\n",
    "    \"\"\"Get predictions from the base model and residuals.\"\"\"\n",
    "    base_pred = base_model.predict(x)\n",
    "    residuals_pred = scaler_y.inverse_transform(\n",
    "        svr_residual.predict(x).reshape(-1, 1)\n",
    "    ).ravel()\n",
    "    return base_pred + residuals_pred\n",
    "\n",
    "# Step 3: Combined prediction\n",
    "y_pred_hybrid = get_predictions(X_test)\n",
    "\n",
    "# Evaluate the hybrid model\n",
    "mse_hybrid = mean_squared_error(y_test, y_pred_hybrid)\n",
    "r2_hybrid = r2_score(y_test, y_pred_hybrid) \n",
    "print(f'Hybrid Model Mean Squared Error: {mse_hybrid}')\n",
    "print(f'Hybrid Model R-squared: {r2_hybrid}')\n",
    "\n",
    "# Plot the hybrid model results\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot actual data as bars using year values\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Actual')\n",
    "# Get corresponding years for test predictions\n",
    "X_test_years = scaler.inverse_transform(X_test)\n",
    "plt.scatter(X_test_years.flatten(), y_pred_hybrid, color='purple',\n",
    "            s=50, label='Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Plot hybrid line\n",
    "X_train_years = scaler.inverse_transform(X_train)\n",
    "plt.plot(X_train_years.flatten(), get_predictions(X_train), color='orange', linewidth=2, label='Base Model Line')\n",
    "plt.title('Hybrid Model Impact Score vs Graduation Year')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Add hybrid model to comparison\n",
    "models['Hybrid Model'] = (mse_hybrid, r2_hybrid)\n",
    "# Final model comparison\n",
    "print(\"\\nFinal Model Comparison with Hybrid Model:\")\n",
    "sorted_models = sorted(models.items(), key=lambda x: x[1][0])  # Sort by MSE\n",
    "for model_name, (mse_value, r2_value) in sorted_models:\n",
    "    print(f\"{model_name:20} - MSE: {mse_value:10.2f}, R²: {r2_value:8.4f}\")\n",
    "\n",
    "# Forecast future values with the hybrid model\n",
    "import numpy as np\n",
    "last_year = years.max()  # Find most recent year in data\n",
    "future_years = np.arange(last_year + 1, last_year + 26).reshape(-1, 1)\n",
    "\n",
    "# Scale future years using the SAME scaler used for training\n",
    "future_years_scaled = scaler.transform(future_years)\n",
    "\n",
    "# Hybrid model prediction\n",
    "future_linear = base_model.predict(future_years_scaled)\n",
    "future_residuals = svr_residual.predict(future_years_scaled)\n",
    "# future_predictions = future_linear + future_residuals\n",
    "future_predictions = get_predictions(future_years_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Historical actual data\n",
    "plt.bar(years, y, color='blue', alpha=0.5, label='Historical Actual')\n",
    "\n",
    "# Historical predictions (from previous plot)\n",
    "plt.scatter(X_test_years.flatten(), y_pred_hybrid, color='purple', \n",
    "            s=50, label='Hybrid Predictions', zorder=5)\n",
    "\n",
    "# Future forecast\n",
    "plt.scatter(future_years, future_predictions, color='red', s=100, \n",
    "           marker='X', label='Forecast', zorder=10)\n",
    "\n",
    "# Trend line extension\n",
    "extended_years = np.vstack([X_train, future_years_scaled])\n",
    "extended_hybrid = get_predictions(extended_years)\n",
    "\n",
    "# Inverse scale years for plotting\n",
    "extended_years_orig = scaler.inverse_transform(extended_years)\n",
    "plt.plot(extended_years_orig, extended_hybrid, 'g--', linewidth=1.5, \n",
    "         label='Forecast Trend')\n",
    "\n",
    "plt.title('Impact Score Forecast (2025-2029)')\n",
    "plt.xlabel('Graduation Year')\n",
    "plt.ylabel('Impact Score')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(np.arange(1950, 2030, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
